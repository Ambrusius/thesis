{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import auc\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "from rapidgbm import RapidGBMTuner\n",
    "\n",
    "import mplhep as hep\n",
    "hep.style.use([hep.style.ATLAS])\n",
    "\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data1 = pd.read_parquet('/groups/hep/kinch/pred_e_m/samples_processed/Zee1.parquetoutput.parquet')\n",
    "data2 = pd.read_parquet('/groups/hep/kinch/pred_e_m/samples_processed/Zee2.parquetoutput.parquet')\n",
    "data3 = pd.read_parquet('/groups/hep/kinch/pred_e_m/samples_processed/Zee3.parquetoutput.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.concat([data1, data2, data3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_list = ['runNumber', 'eventNumber', 'mcEventNumber', 'el_index', 'el_firstEgMotherTruthType',\n",
    "       'el_firstEgMotherTruthOrigin', 'truthType',\n",
    "       'truthOrigin', 'neflowisol20','truthel_e_dressed', \n",
    "       'truthel_pt_dressed', 'truthel_eta_dressed',\n",
    "       'truthel_phi_dressed', 'truthel_m', 'truthel_px', 'truthel_py',\n",
    "       'truthel_pz', 'truthel_E', 'truthel_pdgId', 'truthel_ptcone30',\n",
    "       'truthel_etcone20', 'truthel_ParticleOrigin', 'truthel_Classification',\n",
    "       'truthel_barcode', 'truthel_status', 'truthel_nPhotons_dressed', 'truth_dR', 'm']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['pt', 'eta', 'phi', 'charge', 'f1', 'DNN_pel', 'DNN_pcf', 'DNN_ppc',\n",
      "       'DNN_phf', 'DNN_ple', 'DNN_plh', 'el_DFCommonElectronsECIDS',\n",
      "       'el_DFCommonElectronsECIDSResult', 'GSF_dR', 'GSF_d0', 'GSF_z0',\n",
      "       'GSF_theta', 'GSF_phi', 'GSF_qOverP', 'GSF_chiSquared', 'GSF_var_0',\n",
      "       'GSF_var_1', 'GSF_var_2', 'GSF_var_3', 'GSF_var_4', 'InDet_dR',\n",
      "       'InDet_d0', 'InDet_z0', 'InDet_theta', 'InDet_phi', 'InDet_var_0',\n",
      "       'InDet_var_1', 'InDet_var_2', 'InDet_var_3', 'InDet_var_4',\n",
      "       'ptvarcone20', 'topoetcone20', 'topoetcone40',\n",
      "       'el_ptvarcone30_Nonprompt_All_MaxWeightTTVALooseCone_pt1000',\n",
      "       'el_ptcone20_Nonprompt_All_MaxWeightTTVALooseCone_pt1000',\n",
      "       'el_ptvarcone30_Nonprompt_All_MaxWeightTTVALooseCone_pt1000_CloseByCorr',\n",
      "       'el_topoetcone20_CloseByCorr',\n",
      "       'el_ptcone20_Nonprompt_All_MaxWeightTTVALooseCone_pt1000_CloseByCorr',\n",
      "       'el_core57cellsEnergyCorrection', 'el_topoetcone20ptCorrection',\n",
      "       'el_ptcone20_Nonprompt_All_MaxWeightTTVALooseCone_pt500',\n",
      "       'el_ptvarcone30_Nonprompt_All_MaxWeightTTVALooseCone_pt500'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# split the data\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(data, data['truthel_E'], test_size=0.2, random_state=42)\n",
    "\n",
    "X_test_full = X_test.copy()\n",
    "X_train.drop(drop_list, axis=1, inplace=True)\n",
    "X_test.drop(drop_list, axis=1, inplace=True)\n",
    "print(X_train.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " * Initiating LGBMTuner.fit\n",
      "     . Settings:\n",
      "     .. Trying 30 trials\n",
      "     .. Evaluation metric: mae \n",
      "     .. Study direction: minimize mae\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tuner = RapidGBMTuner(metric='mae', trials=30, refit=True, verbosity=1, visualization=True, seed=414243)#, grid='h,learning_rate')\n",
    "\n",
    "tuner.grid['max_depth'] = (0, 100)\n",
    "tuner.grid['learning_rate'] = (0.00001, 0.1)\n",
    "tuner.grid['drop_rate'] = (0.05,0.4)\n",
    "# Fit tuner for each set of input_data\n",
    "tuner.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "RapidGBMTuner.predict() got an unexpected keyword argument 'return_std'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 6\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# Plot the learning curve\u001b[39;00m\n\u001b[1;32m      5\u001b[0m predictions \u001b[38;5;241m=\u001b[39m tuner\u001b[38;5;241m.\u001b[39mpredict(X_test)\n\u001b[0;32m----> 6\u001b[0m predictions_std \u001b[38;5;241m=\u001b[39m \u001b[43mtuner\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_std\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mTypeError\u001b[0m: RapidGBMTuner.predict() got an unexpected keyword argument 'return_std'"
     ]
    }
   ],
   "source": [
    "plt.rcdefaults()\n",
    "hep.style.use([hep.style.ATLAS])\n",
    "\n",
    "# Plot the learning curve\n",
    "predictions = tuner.predict(X_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
